{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to verify the configurator.py file.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "import socket\n",
    "import tqdm\n",
    "import signal\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "## from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Libraries used for Distributed Data Parallel (DDP)\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from neurorient.model_bifpn     import NeurOrient\n",
    "from neurorient.utils_model     import get_radial_profile\n",
    "from neurorient.data            import TensorDatasetWithTransform\n",
    "from neurorient.image_transform import RandomPatch\n",
    "from neurorient.utils           import init_logger, MetaLog, split_dataset, save_checkpoint, load_checkpoint, set_seed, init_weights\n",
    "from neurorient.configurator    import Configurator\n",
    "from neurorient.lr_scheduler    import CosineLRScheduler\n",
    "from neurorient.config          import _CONFIG\n",
    "from neurorient.utils_config    import prepare_Slice2RotMat_BIFPN_inputs\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)    # [WARNING] Making it True may throw errors when using bfloat16\n",
    "                                            # Reference: https://discuss.pytorch.org/t/convolutionbackward0-returned-nan-values-in-its-0th-output/175571/4\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ ARG ]]]\n",
    "# parser = argparse.ArgumentParser(description=\"Load training configuration from a YAML file to a dictionary.\")\n",
    "# parser.add_argument(\"yaml_file\", help=\"Path to the YAML file\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace(yaml_file='/global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config.1BXR.test.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ HYPER-PARAMERTERS ]]]\n",
    "# Load CONFIG from YAML\n",
    "fl_yaml = args.yaml_file\n",
    "with open(fl_yaml, 'r') as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "CONFIG = Configurator.from_dict(config_dict)\n",
    "\n",
    "# ...Checkpoint\n",
    "timestamp_prev      = CONFIG.CHKPT.TIMESTAMP_PREV\n",
    "epoch_prev          = CONFIG.CHKPT.EPOCH_PREV\n",
    "dir_chkpt           = Path(os.path.join(CONFIG.MISC.BASE_DIRECTORY, CONFIG.CHKPT.DIRECTORY))\n",
    "dir_chkpt.mkdir(parents=True, exist_ok=True)\n",
    "fl_chkpt_prefix     = CONFIG.CHKPT.FILENAME_PREFIX\n",
    "\n",
    "# ...Dataset\n",
    "dir_dataset       = CONFIG.DATASET.DIRECTORY\n",
    "pdb               = CONFIG.DATASET.PDB\n",
    "poisson           = CONFIG.DATASET.POISSON\n",
    "increase_factor   = CONFIG.DATASET.INCREASE_FACTOR\n",
    "num_images        = CONFIG.DATASET.NUM_IMG\n",
    "frac_train        = CONFIG.DATASET.FRAC_TRAIN\n",
    "size_batch        = CONFIG.DATASET.BATCH_SIZE\n",
    "num_workers       = CONFIG.DATASET.NUM_WORKERS\n",
    "uses_random_patch = CONFIG.DATASET.USES_RANDOM_PATCH\n",
    "\n",
    "# ...Model\n",
    "num_bifpn_blocks    = CONFIG.MODEL.BIFPN.NUM_BLOCKS\n",
    "num_bifpn_features  = CONFIG.MODEL.BIFPN.NUM_FEATURES\n",
    "freezes_backbone    = CONFIG.MODEL.FREEZES_BACKBONE\n",
    "uses_random_weights = CONFIG.MODEL.USES_RANDOM_WEIGHTS\n",
    "\n",
    "# ...Optimizer\n",
    "lr           = float(CONFIG.OPTIM.LR)\n",
    "weight_decay = float(CONFIG.OPTIM.WEIGHT_DECAY)\n",
    "grad_clip    = float(CONFIG.OPTIM.GRAD_CLIP)\n",
    "\n",
    "# ...Loss\n",
    "loss_scale_factor = CONFIG.LOSS.SCALE_FACTOR\n",
    "\n",
    "# ...Scheduler\n",
    "## patience = CONFIG.LR_SCHEDULER.PATIENCE\n",
    "warmup_epochs = CONFIG.LR_SCHEDULER.WARMUP_EPOCHS\n",
    "total_epochs  = CONFIG.LR_SCHEDULER.TOTAL_EPOCHS\n",
    "min_lr        = float(CONFIG.LR_SCHEDULER.MIN_LR)\n",
    "\n",
    "# ...DDP\n",
    "ddp_backend            = CONFIG.DDP.BACKEND\n",
    "uses_unique_world_seed = CONFIG.DDP.USES_UNIQUE_WORLD_SEED\n",
    "\n",
    "# ...Logging\n",
    "dir_log       = Path(os.path.join(CONFIG.MISC.BASE_DIRECTORY, CONFIG.LOGGING.DIRECTORY))\n",
    "dir_log.mkdir(parents=True, exist_ok=True)\n",
    "fl_log_prefix = CONFIG.LOGGING.FILENAME_PREFIX\n",
    "\n",
    "# ...Misc\n",
    "uses_mixed_precision = CONFIG.MISC.USES_MIXED_PRECISION\n",
    "max_epochs           = CONFIG.MISC.MAX_EPOCHS\n",
    "num_gpus             = CONFIG.MISC.NUM_GPUS\n",
    "dir_base             = CONFIG.MISC.BASE_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_config = CONFIG.merge_with_priority(_CONFIG, self_has_priority=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DDP is used.  RANK:0,LOCAL_RANK:0,WORLD_SIZE:1\n"
     ]
    }
   ],
   "source": [
    "# Update internal config...\n",
    "# _CONFIG.BIFPN.NUM_BLOCKS           = num_bifpn_blocks\n",
    "# _CONFIG.BIFPN.NUM_FEATURES         = num_bifpn_features\n",
    "# _CONFIG.REGRESSOR_HEAD.IN_FEATURES = num_bifpn_features * 64 * 64\n",
    "\n",
    "\n",
    "# [[[ ERROR HANDLING ]]]\n",
    "def signal_handler(signal, frame):\n",
    "    # Emit Ctrl+C like signal which is then caught by our try/except block\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "# Register the signal handler\n",
    "signal.signal(signal.SIGINT,  signal_handler)\n",
    "signal.signal(signal.SIGTERM, signal_handler)\n",
    "\n",
    "\n",
    "# [[[ DDP INIT ]]]\n",
    "# uses_ddp = int(os.environ.get(\"RANK\", -1)) != -1\n",
    "uses_ddp = True\n",
    "if uses_ddp:\n",
    "    # Initialize distributed environment\n",
    "    ddp_rank       = int(os.environ[\"RANK\"      ])\n",
    "    ddp_local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    ddp_world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    dist.init_process_group(backend=ddp_backend, rank = ddp_rank, world_size = ddp_world_size, init_method = \"env://\")\n",
    "    print(f\"RANK:{ddp_rank},LOCAL_RANK:{ddp_local_rank},WORLD_SIZE:{ddp_world_size}\")\n",
    "else:\n",
    "    ddp_rank       = 0\n",
    "    ddp_local_rank = 0\n",
    "    ddp_world_size = 1\n",
    "    print(f\"NO DDP is used.  RANK:{ddp_rank},LOCAL_RANK:{ddp_local_rank},WORLD_SIZE:{ddp_world_size}\")\n",
    "\n",
    "# Set up GPU device\n",
    "device = f'cuda:{ddp_local_rank}' if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.set_device(device)\n",
    "seed_offset = ddp_rank if uses_unique_world_seed else 0\n",
    "\n",
    "\n",
    "# [[[ USE YAML CONFIG TO INITIALIZE HYPERPARAMETERS ]]]\n",
    "# ...Checkpoint\n",
    "fl_chkpt_prev   = None if timestamp_prev is None else f\"{timestamp_prev}.epoch_{epoch_prev}.chkpt\"\n",
    "path_chkpt_prev = None if fl_chkpt_prev is None else os.path.join(dir_chkpt, fl_chkpt_prev)\n",
    "\n",
    "# Set Seed\n",
    "base_seed   = 0\n",
    "world_seed  = base_seed + seed_offset\n",
    "\n",
    "if ddp_rank == 0:\n",
    "    # Fetch the current timestamp...\n",
    "    timestamp = init_logger(fl_prefix = fl_log_prefix, dir_log = dir_log, returns_timestamp = True)\n",
    "\n",
    "    # Convert dictionary to yaml formatted string...\n",
    "    config_dict = CONFIG.to_dict()\n",
    "    config_yaml = yaml.dump(config_dict)\n",
    "\n",
    "    # Log the config...\n",
    "    logger.info(config_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ DATASET ]]]\n",
    "spi_data = torch.load(os.path.join(dir_dataset, f'{pdb}_increase{increase_factor}_poisson{poisson}_num{num_images//1000}K.pt'))\n",
    "\n",
    "# Set global seed and split data...\n",
    "set_seed(base_seed)\n",
    "data              = spi_data['intensities']\n",
    "spi_data_train    = data[:int(len(data) * frac_train) ]\n",
    "spi_data_validate = data[ int(len(data) * frac_train):]\n",
    "\n",
    "# Set world seed and set up transformation rules\n",
    "set_seed(world_seed)\n",
    "num_patch    = 200\n",
    "size_patch_y = 5\n",
    "size_patch_x = 5\n",
    "var_patch_y  = 0.2\n",
    "var_patch_x  = 0.2\n",
    "returns_mask = False\n",
    "random_patch = RandomPatch(num_patch    = num_patch,\n",
    "                           size_patch_y = size_patch_y,\n",
    "                           size_patch_x = size_patch_x,\n",
    "                           var_patch_y  = var_patch_y,\n",
    "                           var_patch_x  = var_patch_x,\n",
    "                           returns_mask = returns_mask)\n",
    "random_patch = None if uses_random_patch else random_patch    # Janky inline workaround to turn off random patching\n",
    "transform_list = ( random_patch, )\n",
    "\n",
    "dataset_train    = TensorDatasetWithTransform(spi_data_train.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "sampler_train    = torch.utils.data.DistributedSampler(dataset_train) if uses_ddp else None\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                sampler     = sampler_train,\n",
    "                                                shuffle     = False,\n",
    "                                                pin_memory  = True,\n",
    "                                                batch_size  = size_batch,\n",
    "                                                num_workers = num_workers, )\n",
    "\n",
    "dataset_validate    = TensorDatasetWithTransform(spi_data_validate.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "sampler_validate    = torch.utils.data.DistributedSampler(dataset_validate, shuffle=False) if uses_ddp else None\n",
    "dataloader_validate = torch.utils.data.DataLoader( dataset_validate,\n",
    "                                                   sampler     = sampler_validate,\n",
    "                                                   shuffle     = False,\n",
    "                                                   pin_memory  = True,\n",
    "                                                   batch_size  = size_batch,\n",
    "                                                   num_workers = num_workers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeurOrient(\n",
       "  (orientation_predictor): Slice2RotMat(\n",
       "    (resnet): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (volume_predictor): IntensityNet(\n",
       "    (net_mag): SirenNet(\n",
       "      (layers): ModuleList(\n",
       "        (0-4): 5 x Siren(\n",
       "          (activation): Sine()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (last_layer): Siren(\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [[[ MODEL ]]]\n",
    "\n",
    "config_slice2rotmat = prepare_Slice2RotMat_BIFPN_inputs(merged_config, use_bifpn=merged_config.MODEL.USE_BIFPN)\n",
    "model = NeurOrient(spi_data['pixel_position_reciprocal'],\n",
    "                   over_sampling=1, photons_per_pulse=1e13,\n",
    "                   use_bifpn=merged_config.MODEL.USE_BIFPN,\n",
    "                   config_slice2rotmat=config_slice2rotmat,)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437767 M pamameters.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ddp_rank == 0:\n",
    "    print(f\"{sum(p.numel() for p in model.parameters())/1e6} M pamameters.\")\n",
    "\n",
    "# Initialized by the main rank and weights will be broadcast by DDP wrapper\n",
    "# if ddp_rank == 0:\n",
    "#     if uses_random_weights:\n",
    "#         # Use random weights...\n",
    "#         model.apply(init_weights)\n",
    "#     else:\n",
    "#         # [TODO]\n",
    "#         pass\n",
    "\n",
    "# Freeze the backbone???\n",
    "if freezes_backbone:\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "model.float()\n",
    "\n",
    "if uses_ddp:\n",
    "    # Convert BatchNorm to SyncBatchNorm...\n",
    "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "    # Wrap it up using DDP...\n",
    "    model = DDP(model, device_ids = [ddp_local_rank], find_unused_parameters=True)\n",
    "\n",
    "\n",
    "# [[[ CRITERION ]]]\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# [[[ OPTIMIZER ]]]\n",
    "param_iter = model.module.parameters() if hasattr(model, \"module\") else model.parameters()\n",
    "optimizer = optim.AdamW(param_iter,\n",
    "                        lr = lr,\n",
    "                        weight_decay = weight_decay)\n",
    "scheduler = CosineLRScheduler(optimizer     = optimizer,\n",
    "                              warmup_epochs = warmup_epochs,\n",
    "                              total_epochs  = total_epochs,\n",
    "                              min_lr        = min_lr)\n",
    "## scheduler = ReduceLROnPlateau(optimizer, mode           = 'min',\n",
    "##                                          factor         = 2e-1,\n",
    "##                                          patience       = patience,\n",
    "##                                          threshold      = 1e-4,\n",
    "##                                          threshold_mode ='rel',\n",
    "##                                          verbose        = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current timestamp: 2023_0930_1555_03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/250 [00:01<07:41,  1.85s/it]\u001b[A\n",
      "  1%|          | 2/250 [00:02<03:37,  1.14it/s]\u001b[A\n",
      "  1%|          | 3/250 [00:02<02:19,  1.77it/s]\u001b[A\n",
      "  2%|▏         | 4/250 [00:02<01:42,  2.40it/s]\u001b[A\n",
      "  2%|▏         | 5/250 [00:02<01:22,  2.98it/s]\u001b[A\n",
      "  2%|▏         | 6/250 [00:02<01:09,  3.49it/s]\u001b[A\n",
      "  3%|▎         | 7/250 [00:03<01:02,  3.92it/s]\u001b[A\n",
      "  3%|▎         | 8/250 [00:03<00:56,  4.26it/s]\u001b[A\n",
      "  4%|▎         | 9/250 [00:03<00:53,  4.52it/s]\u001b[A\n",
      "  4%|▍         | 10/250 [00:03<00:50,  4.72it/s]\u001b[A\n",
      "  4%|▍         | 11/250 [00:03<00:49,  4.87it/s]\u001b[A\n",
      "  5%|▍         | 12/250 [00:03<00:47,  4.98it/s]\u001b[A\n",
      "  5%|▌         | 13/250 [00:04<01:19,  3.00it/s]\u001b[A\n",
      "  0%|          | 0/1000 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDP RANK 0: Training was interrupted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [[[ TRAIN LOOP ]]]\n",
    "# From a prev training???\n",
    "epoch_min = 0\n",
    "loss_min  = float('inf')\n",
    "if path_chkpt_prev is not None:\n",
    "    epoch_min, loss_min = load_checkpoint(model, optimizer, scheduler, path_chkpt_prev)\n",
    "    ## epoch_min, loss_min = load_checkpoint(model, None, None, path_chkpt_prev)\n",
    "    epoch_min += 1    # Next epoch\n",
    "    logger.info(f\"PREV - epoch_min = {epoch_min}, loss_min = {loss_min}\")\n",
    "\n",
    "if ddp_rank == 0:\n",
    "    print(f\"Current timestamp: {timestamp}\")\n",
    "\n",
    "try:\n",
    "    chkpt_saving_period = 5\n",
    "    epoch_unstable_end  = 40\n",
    "    for epoch in tqdm.tqdm(range(max_epochs)):\n",
    "        epoch += epoch_min\n",
    "\n",
    "        if uses_ddp:\n",
    "            # Shuffle the training examples...\n",
    "            sampler_train.set_epoch(epoch)\n",
    "\n",
    "        # Uses mixed precision???\n",
    "        if uses_mixed_precision: scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        # ___/ TRAIN \\___\n",
    "        # Turn on training related components in the model...\n",
    "        model.train()\n",
    "\n",
    "        # Fetch batches...\n",
    "        batch_train  = tqdm.tqdm(enumerate(dataloader_train), total = len(dataloader_train))\n",
    "        train_loss   = torch.zeros(len(batch_train)).to(device).float()\n",
    "        train_sample = torch.zeros(len(batch_train)).to(device).float()\n",
    "        for batch_idx, batch_entry in batch_train:\n",
    "            # Unpack the batch entry and move them to device...\n",
    "            batch_input, batch_target = batch_entry\n",
    "            batch_input  = batch_input.to(device, dtype = torch.float)\n",
    "            batch_target = batch_target.to(device, dtype = torch.float)\n",
    "\n",
    "            # Use log scale...\n",
    "            batch_target = batch_target * loss_scale_factor + 1.\n",
    "            batch_target = torch.log(batch_target)\n",
    "\n",
    "            # Forward, backward and update...\n",
    "            if uses_mixed_precision:\n",
    "                with torch.cuda.amp.autocast(dtype = torch.float16):\n",
    "                    # Forward pass...\n",
    "                    batch_output = model(batch_input)\n",
    "\n",
    "                    # Calculate the loss...\n",
    "                    loss = criterion(batch_output, batch_target)\n",
    "                    loss = loss.mean()\n",
    "\n",
    "                # Backward pass and optimization...\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                if grad_clip != 0.0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Forward pass...\n",
    "                batch_output = model(batch_input)\n",
    "\n",
    "                # Calculate the loss...\n",
    "                loss = criterion(batch_output, batch_target)\n",
    "                loss = loss.mean()\n",
    "\n",
    "                # Backward pass and optimization...\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                if grad_clip != 0.0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                optimizer.step()\n",
    "\n",
    "            # Reporting...\n",
    "            train_loss  [batch_idx] = loss\n",
    "            train_sample[batch_idx] = len(batch_input)\n",
    "\n",
    "        # Calculate the wegihted mean...\n",
    "        train_loss_sum   = torch.dot(train_loss, train_sample)\n",
    "        train_sample_sum = train_sample.sum()\n",
    "\n",
    "        if uses_ddp:\n",
    "            # Gather training metrics\n",
    "            world_train_loss_sum   = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "            world_train_sample_sum = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "            dist.all_gather(world_train_loss_sum  , train_loss_sum)\n",
    "            dist.all_gather(world_train_sample_sum, train_sample_sum)\n",
    "\n",
    "            world_train_loss_mean = torch.tensor(world_train_loss_sum).sum() / torch.tensor(world_train_sample_sum).sum()\n",
    "        else:\n",
    "            world_train_loss_mean = train_loss_sum / train_sample_sum\n",
    "\n",
    "        if ddp_rank == 0:\n",
    "            logger.info(f\"MSG (device:{device}) - epoch {epoch}, mean train loss = {world_train_loss_mean:.8f}\")\n",
    "\n",
    "\n",
    "        # ___/ VALIDATE \\___\n",
    "        model.eval()\n",
    "\n",
    "        # Fetch batches...\n",
    "        batch_validate  = tqdm.tqdm(enumerate(dataloader_validate), total = len(dataloader_validate))\n",
    "        validate_loss   = torch.zeros(len(batch_validate)).to(device).float()\n",
    "        validate_sample = torch.zeros(len(batch_validate)).to(device).float()\n",
    "        for batch_idx, batch_entry in batch_validate:\n",
    "            \"\"\"\n",
    "            Work on any preprocessing when necessary\n",
    "            \"\"\"\n",
    "            # Unpack the batch entry and move them to device...\n",
    "            batch_input, batch_target = batch_entry\n",
    "            batch_input  = batch_input.to(device, dtype = torch.float)\n",
    "            batch_target = batch_target.to(device, dtype = torch.float)\n",
    "\n",
    "            # Use log scale...\n",
    "            batch_target = batch_target * loss_scale_factor + 1.\n",
    "            batch_target = torch.log(batch_target)\n",
    "\n",
    "            # Forward only...\n",
    "            with torch.no_grad():\n",
    "                if uses_mixed_precision:\n",
    "                    with torch.cuda.amp.autocast(dtype = torch.float16):\n",
    "                        # Forward pass...\n",
    "                        batch_output = model(batch_input)\n",
    "\n",
    "                        # Calculate the loss...\n",
    "                        loss = criterion(batch_output, batch_target)\n",
    "                        loss = loss.mean()\n",
    "                else:\n",
    "                    # Forward pass...\n",
    "                    batch_output = model(batch_input)\n",
    "\n",
    "                    # Calculate the loss...\n",
    "                    loss = criterion(batch_output, batch_target)\n",
    "                    loss = loss.mean()\n",
    "\n",
    "            # Reporting...\n",
    "            validate_loss  [batch_idx] = loss\n",
    "            validate_sample[batch_idx] = len(batch_input)\n",
    "\n",
    "        # Calculate the wegihted mean...\n",
    "        validate_loss_sum   = torch.dot(validate_loss, validate_sample)\n",
    "        validate_sample_sum = validate_sample.sum()\n",
    "\n",
    "        if uses_ddp:\n",
    "            # Gather training metrics\n",
    "            world_validate_loss_sum   = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "            world_validate_sample_sum = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "            dist.all_gather(world_validate_loss_sum  , validate_loss_sum)\n",
    "            dist.all_gather(world_validate_sample_sum, validate_sample_sum)\n",
    "\n",
    "            world_validate_loss_mean = torch.tensor(world_validate_loss_sum).sum() / torch.tensor(world_validate_sample_sum).sum() \\\n",
    "                                       if len(spi_data_validate) else                                                              \\\n",
    "                                       world_train_loss_mean\n",
    "        else:\n",
    "            world_validate_loss_mean = validate_loss_sum / validate_sample_sum \\\n",
    "                                       if len(spi_data_validate) else          \\\n",
    "                                       world_train_loss_mean\n",
    "\n",
    "        if ddp_rank == 0:\n",
    "            logger.info(f\"MSG (device:{device}) - epoch {epoch}, mean val   loss = {world_validate_loss_mean:.8f}\")\n",
    "\n",
    "            # Report the learning rate used in the last optimization...\n",
    "            lr_used = optimizer.param_groups[0]['lr']\n",
    "            logger.info(f\"MSG (device:{device}) - epoch {epoch}, lr used = {lr_used:.8f}\")\n",
    "\n",
    "        # Update learning rate in the scheduler...\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        # ___/ SAVE CHECKPOINT??? \\___\n",
    "        if ddp_rank == 0:\n",
    "            if world_validate_loss_mean < loss_min:\n",
    "                loss_min = world_validate_loss_mean\n",
    "\n",
    "                if (epoch % chkpt_saving_period == 0) or (epoch > epoch_unstable_end):\n",
    "                    fl_chkpt = f\"{timestamp}.epoch_{epoch}.chkpt\"\n",
    "                    if fl_chkpt_prefix is not None: fl_chkpt = f\"{fl_chkpt_prefix}.{fl_chkpt}\"\n",
    "                    path_chkpt = os.path.join(dir_chkpt, fl_chkpt)\n",
    "                    save_checkpoint(model, optimizer, scheduler, epoch, loss_min, path_chkpt)\n",
    "                    logger.info(f\"MSG (device:{device}) - save {path_chkpt}\")\n",
    "\n",
    "        if uses_ddp: dist.barrier()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"DDP RANK {ddp_rank}: Training was interrupted!\")\n",
    "except Exception as e:\n",
    "    print(f\"DDP RANK {ddp_rank}: Error occurred: {e}\")\n",
    "finally:\n",
    "    # Ensure that the process group is always destroyed\n",
    "    if dist.is_initialized():\n",
    "        dist.destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "om",
   "language": "python",
   "name": "om"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
