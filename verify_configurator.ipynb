{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to verify the configurator.py file.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from neurorient.model     import NeurOrientLightning\n",
    "from neurorient.data            import TensorDatasetWithTransform\n",
    "from neurorient.logger          import Logger\n",
    "from neurorient.image_transform import RandomPatch\n",
    "from neurorient.configurator    import Configurator\n",
    "# from neurorient.lr_scheduler    import CosineLRScheduler\n",
    "from neurorient.config          import _CONFIG\n",
    "from neurorient.utils_config    import prepare_Slice2RotMat_config, prepare_optimization_config\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)    # [WARNING] Making it True may throw errors when using bfloat16\n",
    "                                            # Reference: https://discuss.pytorch.org/t/convolutionbackward0-returned-nan-values-in-its-0th-output/175571/4\n",
    "                                            \n",
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ ARG ]]]\n",
    "# parser = argparse.ArgumentParser(description=\"Load training configuration from a YAML file to a dictionary.\")\n",
    "# parser.add_argument(\"yaml_file\", help=\"Path to the YAML file\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    yaml_file='/global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config_resnet_bifpn_coslr.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-01 00:15:47] loaded configuration from yaml_file: /global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config_resnet_bifpn_coslr.yaml.\n",
      "[2023-10-01 00:15:47] overwrite default model configurations with customed configurations.\n",
      "[2023-10-01 00:15:47] checkpoints will be saved to /pscratch/sd/z/zhantao/neurorient_repo/chkpts.\n",
      "[2023-10-01 00:15:47] data read from 1BXR_increase10_poissonTrue_num10K.pt\n",
      "[2023-10-01 00:15:47] training the model with 1000 epochs and 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "# [[[ HYPER-PARAMERTERS ]]]\n",
    "# Load CONFIG from YAML\n",
    "fl_yaml = args.yaml_file\n",
    "\n",
    "with open(fl_yaml, 'r') as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "CONFIG = Configurator.from_dict(config_dict)\n",
    "logger.log(f\"loaded configuration from yaml_file: {fl_yaml}.\")\n",
    "\n",
    "merged_config = CONFIG.merge_with_priority(_CONFIG, self_has_priority=True)\n",
    "logger.log(f\"overwrite default model configurations with customed configurations.\")\n",
    "\n",
    "# ...Checkpoint\n",
    "dir_chkpt           = Path(os.path.join(merged_config.TRAINING.BASE_DIRECTORY, merged_config.TRAINING.CHKPT_DIRECTORY))\n",
    "dir_chkpt.mkdir(parents=True, exist_ok=True)\n",
    "logger.log(f\"checkpoints will be saved to {dir_chkpt}.\")\n",
    "\n",
    "# ...Dataset\n",
    "dir_dataset       = merged_config.DATASET.DATASET_DIRECTORY\n",
    "# necessary info to fetch data file name\n",
    "pdb               = merged_config.DATASET.PDB\n",
    "poisson           = merged_config.DATASET.POISSON\n",
    "increase_factor   = merged_config.DATASET.INCREASE_FACTOR\n",
    "num_images        = merged_config.DATASET.NUM_IMG\n",
    "data_file_name = f'{pdb}_increase{increase_factor}_poisson{poisson}_num{num_images//1000}K.pt'\n",
    "logger.log(f'data read from {data_file_name}')\n",
    "\n",
    "# necessary info to define datasets\n",
    "frac_train        = merged_config.DATASET.FRAC_TRAIN\n",
    "size_batch        = merged_config.DATASET.BATCH_SIZE\n",
    "num_workers       = merged_config.DATASET.NUM_WORKERS\n",
    "uses_random_patch = merged_config.DATASET.USES_RANDOM_PATCH\n",
    "\n",
    "\n",
    "# ...Training\n",
    "max_epochs           = merged_config.TRAINING.MAX_EPOCHS\n",
    "num_gpus             = min(torch.cuda.device_count(), merged_config.TRAINING.NUM_GPUS)\n",
    "logger.log(f'training the model with {max_epochs} epochs and {num_gpus} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-01 00:15:48] created training dataset with 9000 images and validation dataset with 1000 images.\n"
     ]
    }
   ],
   "source": [
    "# [[[ DATASET ]]]\n",
    "spi_data = torch.load(os.path.join(dir_dataset, data_file_name))\n",
    "\n",
    "# Set global seed and split data...\n",
    "data              = spi_data['intensities']\n",
    "spi_data_train    = data[:int(len(data) * frac_train) ]\n",
    "spi_data_validate = data[ int(len(data) * frac_train):]\n",
    "\n",
    "# Set world seed and set up transformation rules\n",
    "if uses_random_patch:\n",
    "    num_patch    = 200\n",
    "    size_patch_y = 5\n",
    "    size_patch_x = 5\n",
    "    var_patch_y  = 0.2\n",
    "    var_patch_x  = 0.2\n",
    "    returns_mask = False\n",
    "    random_patch = RandomPatch(num_patch    = num_patch,\n",
    "                               size_patch_y    = size_patch_y,\n",
    "                               size_patch_x    = size_patch_x,\n",
    "                               var_patch_y     = var_patch_y,\n",
    "                               var_patch_x     = var_patch_x,\n",
    "                               returns_mask    = returns_mask)\n",
    "    transform_list   = ( random_patch, )\n",
    "    dataset_train    = TensorDatasetWithTransform(spi_data_train.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "    dataset_validate = TensorDatasetWithTransform(spi_data_validate.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "else:\n",
    "    dataset_train    = TensorDataset(spi_data_train.unsqueeze(1))\n",
    "    dataset_validate = TensorDataset(spi_data_validate.unsqueeze(1))\n",
    "\n",
    "logger.log(f'created training dataset with {len(dataset_train)} images and validation dataset with {len(dataset_validate)} images.')\n",
    "    \n",
    "\n",
    "# lightning will handle the samplers for those dataloaders\n",
    "sampler_train    = None\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                sampler     = sampler_train,\n",
    "                                                shuffle     = True,\n",
    "                                                pin_memory  = True,\n",
    "                                                batch_size  = size_batch,\n",
    "                                                num_workers = num_workers, )\n",
    "\n",
    "sampler_validate    = None\n",
    "dataloader_validate = torch.utils.data.DataLoader( dataset_validate,\n",
    "                                                   sampler     = sampler_validate,\n",
    "                                                   shuffle     = False,\n",
    "                                                   pin_memory  = True,\n",
    "                                                   batch_size  = size_batch,\n",
    "                                                   num_workers = num_workers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-01 00:15:48] arguments being used in building the model:\n",
      " over_sampling=1.0\n",
      " photons_per_pulse=1.00e+13\n",
      " config_slice2rotmat:  \n",
      " {'size': 18, 'pretrained': True} \n",
      " config_optimization:  \n",
      " {'lr': 0.0003, 'weight_decay': 0.0001, 'loss_func': 'MSELoss', 'scheduler': {'name': 'CosineLRScheduler', 'warmup_epochs': 5, 'total_epochs': 1000, 'min_lr': 1e-07}}\n"
     ]
    }
   ],
   "source": [
    "# [[[ MODEL ]]]\n",
    "over_sampling = merged_config.MODEL.OVERSAMPLING\n",
    "photons_per_pulse = merged_config.DATASET.INCREASE_FACTOR * 1e12\n",
    "config_optimization = prepare_optimization_config(merged_config)\n",
    "config_slice2rotmat = prepare_Slice2RotMat_config(merged_config)\n",
    "model = NeurOrientLightning(\n",
    "    spi_data['pixel_position_reciprocal'],\n",
    "    over_sampling=over_sampling, \n",
    "    photons_per_pulse=photons_per_pulse,\n",
    "    use_bifpn=merged_config.MODEL.USE_BIFPN,\n",
    "    config_slice2rotmat=config_slice2rotmat,\n",
    "    config_optimization=config_optimization\n",
    ")\n",
    "logger.log( \n",
    "    'arguments being used in building the model:\\n',\n",
    "    f'over_sampling={over_sampling}\\n',\n",
    "    f'photons_per_pulse={photons_per_pulse:.2e}\\n',\n",
    "    'config_slice2rotmat: ', '\\n', config_slice2rotmat, '\\n',\n",
    "    'config_optimization: ', '\\n', config_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"val_loss\",\n",
    "    filename=f'{pdb}-{{epoch}}-{{step}}'\n",
    ")\n",
    "\n",
    "if merged_config.TRAINING.USES_MIXED_PRECISION:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs, accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=num_gpus,\n",
    "    enable_checkpointing=True, default_root_dir=dir_chkpt)\n",
    "\n",
    "# dump configuration to file for later reference\n",
    "dump_yaml_fname = Path(os.path.join(trainer.logger.save_dir, 'lightning_logs', f'version_{trainer.logger.version}', 'input.yaml'))\n",
    "dump_yaml_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "merged_config.dump_to_file(dump_yaml_fname)\n",
    "\n",
    "dump_log_fname = Path(os.path.join(trainer.logger.save_dir, 'lightning_logs', f'version_{trainer.logger.version}', 'log.txt'))\n",
    "dump_log_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "logger.dump_to_file(dump_log_fname)\n",
    "\n",
    "# trainer.fit(model, dataloader_train, dataloader_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "om",
   "language": "python",
   "name": "om"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
