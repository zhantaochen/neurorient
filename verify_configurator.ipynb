{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to verify the configurator.py file.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "import socket\n",
    "import tqdm\n",
    "import signal\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "## from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Libraries used for Distributed Data Parallel (DDP)\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from neurorient.model     import NeurOrientLightning\n",
    "from neurorient.utils_model     import get_radial_profile\n",
    "from neurorient.data            import TensorDatasetWithTransform\n",
    "from neurorient.image_transform import RandomPatch\n",
    "from neurorient.utils           import init_logger, MetaLog, split_dataset, save_checkpoint, load_checkpoint, set_seed, init_weights\n",
    "from neurorient.configurator    import Configurator\n",
    "from neurorient.lr_scheduler    import CosineLRScheduler\n",
    "from neurorient.config          import _CONFIG\n",
    "from neurorient.utils_config    import prepare_Slice2RotMat_BIFPN_inputs\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)    # [WARNING] Making it True may throw errors when using bfloat16\n",
    "                                            # Reference: https://discuss.pytorch.org/t/convolutionbackward0-returned-nan-values-in-its-0th-output/175571/4\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ ARG ]]]\n",
    "# parser = argparse.ArgumentParser(description=\"Load training configuration from a YAML file to a dictionary.\")\n",
    "# parser.add_argument(\"yaml_file\", help=\"Path to the YAML file\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace(yaml_file='/global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config.1BXR.test.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ HYPER-PARAMERTERS ]]]\n",
    "# Load CONFIG from YAML\n",
    "fl_yaml = args.yaml_file\n",
    "with open(fl_yaml, 'r') as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "CONFIG = Configurator.from_dict(config_dict)\n",
    "\n",
    "# ...Checkpoint\n",
    "timestamp_prev      = CONFIG.CHKPT.TIMESTAMP_PREV\n",
    "epoch_prev          = CONFIG.CHKPT.EPOCH_PREV\n",
    "dir_chkpt           = Path(os.path.join(CONFIG.MISC.BASE_DIRECTORY, CONFIG.CHKPT.DIRECTORY))\n",
    "dir_chkpt.mkdir(parents=True, exist_ok=True)\n",
    "fl_chkpt_prefix     = CONFIG.CHKPT.FILENAME_PREFIX\n",
    "\n",
    "# ...Dataset\n",
    "dir_dataset       = CONFIG.DATASET.DIRECTORY\n",
    "pdb               = CONFIG.DATASET.PDB\n",
    "poisson           = CONFIG.DATASET.POISSON\n",
    "increase_factor   = CONFIG.DATASET.INCREASE_FACTOR\n",
    "num_images        = CONFIG.DATASET.NUM_IMG\n",
    "frac_train        = CONFIG.DATASET.FRAC_TRAIN\n",
    "size_batch        = CONFIG.DATASET.BATCH_SIZE\n",
    "num_workers       = CONFIG.DATASET.NUM_WORKERS\n",
    "uses_random_patch = CONFIG.DATASET.USES_RANDOM_PATCH\n",
    "\n",
    "# ...Model\n",
    "num_bifpn_blocks    = CONFIG.MODEL.BIFPN.NUM_BLOCKS\n",
    "num_bifpn_features  = CONFIG.MODEL.BIFPN.NUM_FEATURES\n",
    "freezes_backbone    = CONFIG.MODEL.FREEZES_BACKBONE\n",
    "uses_random_weights = CONFIG.MODEL.USES_RANDOM_WEIGHTS\n",
    "\n",
    "# ...Optimizer\n",
    "lr           = float(CONFIG.OPTIM.LR)\n",
    "weight_decay = float(CONFIG.OPTIM.WEIGHT_DECAY)\n",
    "grad_clip    = float(CONFIG.OPTIM.GRAD_CLIP)\n",
    "\n",
    "# ...Loss\n",
    "loss_scale_factor = CONFIG.LOSS.SCALE_FACTOR\n",
    "\n",
    "# ...Scheduler\n",
    "## patience = CONFIG.LR_SCHEDULER.PATIENCE\n",
    "warmup_epochs = CONFIG.LR_SCHEDULER.WARMUP_EPOCHS\n",
    "total_epochs  = CONFIG.LR_SCHEDULER.TOTAL_EPOCHS\n",
    "min_lr        = float(CONFIG.LR_SCHEDULER.MIN_LR)\n",
    "\n",
    "# ...DDP\n",
    "ddp_backend            = CONFIG.DDP.BACKEND\n",
    "uses_unique_world_seed = CONFIG.DDP.USES_UNIQUE_WORLD_SEED\n",
    "\n",
    "# ...Logging\n",
    "dir_log       = Path(os.path.join(CONFIG.MISC.BASE_DIRECTORY, CONFIG.LOGGING.DIRECTORY))\n",
    "dir_log.mkdir(parents=True, exist_ok=True)\n",
    "fl_log_prefix = CONFIG.LOGGING.FILENAME_PREFIX\n",
    "\n",
    "# ...Misc\n",
    "uses_mixed_precision = CONFIG.MISC.USES_MIXED_PRECISION\n",
    "max_epochs           = CONFIG.MISC.MAX_EPOCHS\n",
    "num_gpus             = CONFIG.MISC.NUM_GPUS\n",
    "dir_base             = CONFIG.MISC.BASE_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_config = CONFIG.merge_with_priority(_CONFIG, self_has_priority=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_config.dump_to_file('./test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uses_ddp = True\n",
    "\n",
    "# [[[ DATASET ]]]\n",
    "spi_data = torch.load(os.path.join(dir_dataset, f'{pdb}_increase{increase_factor}_poisson{poisson}_num{num_images//1000}K.pt'))\n",
    "\n",
    "# Set global seed and split data...\n",
    "# set_seed(base_seed)\n",
    "data              = spi_data['intensities']\n",
    "spi_data_train    = data[:int(len(data) * frac_train) ]\n",
    "spi_data_validate = data[ int(len(data) * frac_train):]\n",
    "\n",
    "# Set world seed and set up transformation rules\n",
    "# set_seed(world_seed)\n",
    "num_patch    = 200\n",
    "size_patch_y = 5\n",
    "size_patch_x = 5\n",
    "var_patch_y  = 0.2\n",
    "var_patch_x  = 0.2\n",
    "returns_mask = False\n",
    "random_patch = RandomPatch(num_patch    = num_patch,\n",
    "                           size_patch_y = size_patch_y,\n",
    "                           size_patch_x = size_patch_x,\n",
    "                           var_patch_y  = var_patch_y,\n",
    "                           var_patch_x  = var_patch_x,\n",
    "                           returns_mask = returns_mask)\n",
    "random_patch = None if uses_random_patch else random_patch    # Janky inline workaround to turn off random patching\n",
    "transform_list = ( random_patch, )\n",
    "\n",
    "dataset_train    = TensorDatasetWithTransform(spi_data_train.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "# sampler_train    = torch.utils.data.DistributedSampler(dataset_train) if uses_ddp else None\n",
    "sampler_train    = None\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                sampler     = sampler_train,\n",
    "                                                shuffle     = False,\n",
    "                                                pin_memory  = True,\n",
    "                                                batch_size  = size_batch,\n",
    "                                                num_workers = num_workers, )\n",
    "\n",
    "dataset_validate    = TensorDatasetWithTransform(spi_data_validate.unsqueeze(1).numpy(), transform_list = transform_list, uses_norm = False)\n",
    "# sampler_validate    = torch.utils.data.DistributedSampler(dataset_validate, shuffle=False) if uses_ddp else None\n",
    "sampler_validate    = None\n",
    "dataloader_validate = torch.utils.data.DataLoader( dataset_validate,\n",
    "                                                   sampler     = sampler_validate,\n",
    "                                                   shuffle     = False,\n",
    "                                                   pin_memory  = True,\n",
    "                                                   batch_size  = size_batch,\n",
    "                                                   num_workers = num_workers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ MODEL ]]]\n",
    "\n",
    "config_slice2rotmat = prepare_Slice2RotMat_BIFPN_inputs(merged_config, use_bifpn=merged_config.MODEL.USE_BIFPN)\n",
    "model = NeurOrientLightning(\n",
    "    spi_data['pixel_position_reciprocal'],\n",
    "    over_sampling=1, photons_per_pulse=1e13,\n",
    "    use_bifpn=merged_config.MODEL.USE_BIFPN,\n",
    "    config_slice2rotmat=config_slice2rotmat,\n",
    "    config_optimization={'lr': lr, 'weight_decay': weight_decay, 'loss_func': 'MSELoss'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"val_loss\",\n",
    "    filename=f'{pdb}-{{epoch}}-{{step}}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /pscratch/sd/z/zhantao/neurorient_repo/chkpts/lightning_logs/version_16442918/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model     | NeurOrient | 11.4 M\n",
      "1 | loss_func | MSELoss    | 0     \n",
      "-----------------------------------------\n",
      "11.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.751    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db127b388e924f5c81ee738ca3b18b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e6e60727f4674bf07936b4c25d7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs, accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=num_gpus,\n",
    "    enable_checkpointing=True, default_root_dir=dir_chkpt)\n",
    "trainer.fit(model, dataloader_train, dataloader_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_log_fname = Path(os.path.join(trainer.logger.save_dir, 'lightning_logs', f'version_{trainer.logger.version}', 'input.yaml'))\n",
    "input_log_fname.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_config.dump_to_file(input_log_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# if ddp_rank == 0:\n",
    "#     print(f\"{sum(p.numel() for p in model.parameters())/1e6} M pamameters.\")\n",
    "\n",
    "# # Initialized by the main rank and weights will be broadcast by DDP wrapper\n",
    "# # if ddp_rank == 0:\n",
    "# #     if uses_random_weights:\n",
    "# #         # Use random weights...\n",
    "# #         model.apply(init_weights)\n",
    "# #     else:\n",
    "# #         # [TODO]\n",
    "# #         pass\n",
    "\n",
    "# # Freeze the backbone???\n",
    "# if freezes_backbone:\n",
    "#     for param in model.backbone.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "# model.float()\n",
    "\n",
    "# if uses_ddp:\n",
    "#     # Convert BatchNorm to SyncBatchNorm...\n",
    "#     model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "#     # Wrap it up using DDP...\n",
    "#     model = DDP(model, device_ids = [ddp_local_rank], find_unused_parameters=True)\n",
    "\n",
    "\n",
    "# [[[ CRITERION ]]]\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# [[[ OPTIMIZER ]]]\n",
    "# param_iter = model.module.parameters() if hasattr(model, \"module\") else model.parameters()\n",
    "# optimizer = optim.AdamW(param_iter,\n",
    "#                         lr = lr,\n",
    "#                         weight_decay = weight_decay)\n",
    "# scheduler = CosineLRScheduler(optimizer     = optimizer,\n",
    "#                               warmup_epochs = warmup_epochs,\n",
    "#                               total_epochs  = total_epochs,\n",
    "#                               min_lr        = min_lr)\n",
    "## scheduler = ReduceLROnPlateau(optimizer, mode           = 'min',\n",
    "##                                          factor         = 2e-1,\n",
    "##                                          patience       = patience,\n",
    "##                                          threshold      = 1e-4,\n",
    "##                                          threshold_mode ='rel',\n",
    "##                                          verbose        = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # [[[ TRAIN LOOP ]]]\n",
    "# # From a prev training???\n",
    "# epoch_min = 0\n",
    "# loss_min  = float('inf')\n",
    "# if path_chkpt_prev is not None:\n",
    "#     epoch_min, loss_min = load_checkpoint(model, optimizer, scheduler, path_chkpt_prev)\n",
    "#     ## epoch_min, loss_min = load_checkpoint(model, None, None, path_chkpt_prev)\n",
    "#     epoch_min += 1    # Next epoch\n",
    "#     logger.info(f\"PREV - epoch_min = {epoch_min}, loss_min = {loss_min}\")\n",
    "\n",
    "# if ddp_rank == 0:\n",
    "#     print(f\"Current timestamp: {timestamp}\")\n",
    "\n",
    "# try:\n",
    "#     chkpt_saving_period = 5\n",
    "#     epoch_unstable_end  = 40\n",
    "#     for epoch in tqdm.tqdm(range(max_epochs)):\n",
    "#         epoch += epoch_min\n",
    "\n",
    "#         if uses_ddp:\n",
    "#             # Shuffle the training examples...\n",
    "#             sampler_train.set_epoch(epoch)\n",
    "\n",
    "#         # Uses mixed precision???\n",
    "#         if uses_mixed_precision: scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "#         # ___/ TRAIN \\___\n",
    "#         # Turn on training related components in the model...\n",
    "#         model.train()\n",
    "\n",
    "#         # Fetch batches...\n",
    "#         batch_train  = tqdm.tqdm(enumerate(dataloader_train), total = len(dataloader_train))\n",
    "#         train_loss   = torch.zeros(len(batch_train)).to(device).float()\n",
    "#         train_sample = torch.zeros(len(batch_train)).to(device).float()\n",
    "#         for batch_idx, batch_entry in batch_train:\n",
    "#             # Unpack the batch entry and move them to device...\n",
    "#             batch_input, batch_target = batch_entry\n",
    "#             batch_input  = batch_input.to(device, dtype = torch.float)\n",
    "#             batch_target = batch_target.to(device, dtype = torch.float)\n",
    "\n",
    "#             # Use log scale...\n",
    "#             batch_target = batch_target * loss_scale_factor + 1.\n",
    "#             batch_target = torch.log(batch_target)\n",
    "\n",
    "#             # Forward, backward and update...\n",
    "#             if uses_mixed_precision:\n",
    "#                 with torch.cuda.amp.autocast(dtype = torch.float16):\n",
    "#                     # Forward pass...\n",
    "#                     batch_output = model(batch_input)\n",
    "\n",
    "#                     # Calculate the loss...\n",
    "#                     loss = criterion(batch_output, batch_target)\n",
    "#                     loss = loss.mean()\n",
    "\n",
    "#                 # Backward pass and optimization...\n",
    "#                 optimizer.zero_grad()\n",
    "#                 scaler.scale(loss).backward()\n",
    "#                 if grad_clip != 0.0:\n",
    "#                     scaler.unscale_(optimizer)\n",
    "#                     torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "#                 scaler.step(optimizer)\n",
    "#                 scaler.update()\n",
    "#             else:\n",
    "#                 # Forward pass...\n",
    "#                 batch_output = model(batch_input)\n",
    "\n",
    "#                 # Calculate the loss...\n",
    "#                 loss = criterion(batch_output, batch_target)\n",
    "#                 loss = loss.mean()\n",
    "\n",
    "#                 # Backward pass and optimization...\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 if grad_clip != 0.0:\n",
    "#                     torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "#                 optimizer.step()\n",
    "\n",
    "#             # Reporting...\n",
    "#             train_loss  [batch_idx] = loss\n",
    "#             train_sample[batch_idx] = len(batch_input)\n",
    "\n",
    "#         # Calculate the wegihted mean...\n",
    "#         train_loss_sum   = torch.dot(train_loss, train_sample)\n",
    "#         train_sample_sum = train_sample.sum()\n",
    "\n",
    "#         if uses_ddp:\n",
    "#             # Gather training metrics\n",
    "#             world_train_loss_sum   = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "#             world_train_sample_sum = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "#             dist.all_gather(world_train_loss_sum  , train_loss_sum)\n",
    "#             dist.all_gather(world_train_sample_sum, train_sample_sum)\n",
    "\n",
    "#             world_train_loss_mean = torch.tensor(world_train_loss_sum).sum() / torch.tensor(world_train_sample_sum).sum()\n",
    "#         else:\n",
    "#             world_train_loss_mean = train_loss_sum / train_sample_sum\n",
    "\n",
    "#         if ddp_rank == 0:\n",
    "#             logger.info(f\"MSG (device:{device}) - epoch {epoch}, mean train loss = {world_train_loss_mean:.8f}\")\n",
    "\n",
    "\n",
    "#         # ___/ VALIDATE \\___\n",
    "#         model.eval()\n",
    "\n",
    "#         # Fetch batches...\n",
    "#         batch_validate  = tqdm.tqdm(enumerate(dataloader_validate), total = len(dataloader_validate))\n",
    "#         validate_loss   = torch.zeros(len(batch_validate)).to(device).float()\n",
    "#         validate_sample = torch.zeros(len(batch_validate)).to(device).float()\n",
    "#         for batch_idx, batch_entry in batch_validate:\n",
    "#             \"\"\"\n",
    "#             Work on any preprocessing when necessary\n",
    "#             \"\"\"\n",
    "#             # Unpack the batch entry and move them to device...\n",
    "#             batch_input, batch_target = batch_entry\n",
    "#             batch_input  = batch_input.to(device, dtype = torch.float)\n",
    "#             batch_target = batch_target.to(device, dtype = torch.float)\n",
    "\n",
    "#             # Use log scale...\n",
    "#             batch_target = batch_target * loss_scale_factor + 1.\n",
    "#             batch_target = torch.log(batch_target)\n",
    "\n",
    "#             # Forward only...\n",
    "#             with torch.no_grad():\n",
    "#                 if uses_mixed_precision:\n",
    "#                     with torch.cuda.amp.autocast(dtype = torch.float16):\n",
    "#                         # Forward pass...\n",
    "#                         batch_output = model(batch_input)\n",
    "\n",
    "#                         # Calculate the loss...\n",
    "#                         loss = criterion(batch_output, batch_target)\n",
    "#                         loss = loss.mean()\n",
    "#                 else:\n",
    "#                     # Forward pass...\n",
    "#                     batch_output = model(batch_input)\n",
    "\n",
    "#                     # Calculate the loss...\n",
    "#                     loss = criterion(batch_output, batch_target)\n",
    "#                     loss = loss.mean()\n",
    "\n",
    "#             # Reporting...\n",
    "#             validate_loss  [batch_idx] = loss\n",
    "#             validate_sample[batch_idx] = len(batch_input)\n",
    "\n",
    "#         # Calculate the wegihted mean...\n",
    "#         validate_loss_sum   = torch.dot(validate_loss, validate_sample)\n",
    "#         validate_sample_sum = validate_sample.sum()\n",
    "\n",
    "#         if uses_ddp:\n",
    "#             # Gather training metrics\n",
    "#             world_validate_loss_sum   = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "#             world_validate_sample_sum = [ torch.tensor(0.0).to(device).float() for _ in range(ddp_world_size) ]\n",
    "#             dist.all_gather(world_validate_loss_sum  , validate_loss_sum)\n",
    "#             dist.all_gather(world_validate_sample_sum, validate_sample_sum)\n",
    "\n",
    "#             world_validate_loss_mean = torch.tensor(world_validate_loss_sum).sum() / torch.tensor(world_validate_sample_sum).sum() \\\n",
    "#                                        if len(spi_data_validate) else                                                              \\\n",
    "#                                        world_train_loss_mean\n",
    "#         else:\n",
    "#             world_validate_loss_mean = validate_loss_sum / validate_sample_sum \\\n",
    "#                                        if len(spi_data_validate) else          \\\n",
    "#                                        world_train_loss_mean\n",
    "\n",
    "#         if ddp_rank == 0:\n",
    "#             logger.info(f\"MSG (device:{device}) - epoch {epoch}, mean val   loss = {world_validate_loss_mean:.8f}\")\n",
    "\n",
    "#             # Report the learning rate used in the last optimization...\n",
    "#             lr_used = optimizer.param_groups[0]['lr']\n",
    "#             logger.info(f\"MSG (device:{device}) - epoch {epoch}, lr used = {lr_used:.8f}\")\n",
    "\n",
    "#         # Update learning rate in the scheduler...\n",
    "#         scheduler.step()\n",
    "\n",
    "\n",
    "#         # ___/ SAVE CHECKPOINT??? \\___\n",
    "#         if ddp_rank == 0:\n",
    "#             if world_validate_loss_mean < loss_min:\n",
    "#                 loss_min = world_validate_loss_mean\n",
    "\n",
    "#                 if (epoch % chkpt_saving_period == 0) or (epoch > epoch_unstable_end):\n",
    "#                     fl_chkpt = f\"{timestamp}.epoch_{epoch}.chkpt\"\n",
    "#                     if fl_chkpt_prefix is not None: fl_chkpt = f\"{fl_chkpt_prefix}.{fl_chkpt}\"\n",
    "#                     path_chkpt = os.path.join(dir_chkpt, fl_chkpt)\n",
    "#                     save_checkpoint(model, optimizer, scheduler, epoch, loss_min, path_chkpt)\n",
    "#                     logger.info(f\"MSG (device:{device}) - save {path_chkpt}\")\n",
    "\n",
    "#         if uses_ddp: dist.barrier()\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print(f\"DDP RANK {ddp_rank}: Training was interrupted!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"DDP RANK {ddp_rank}: Error occurred: {e}\")\n",
    "# finally:\n",
    "#     # Ensure that the process group is always destroyed\n",
    "#     if dist.is_initialized():\n",
    "#         dist.destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "om",
   "language": "python",
   "name": "om"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
