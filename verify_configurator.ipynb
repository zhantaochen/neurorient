{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to verify the configurator.py file.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "from neurorient.model           import NeurOrientLightning\n",
    "from neurorient.dataset         import TensorDatasetWithTransform\n",
    "from neurorient.logger          import Logger\n",
    "from neurorient.image_transform import RandomPatch, PhotonFluctuation, PoissonNoise, BeamStopMask\n",
    "from neurorient.configurator    import Configurator\n",
    "# from neurorient.lr_scheduler    import CosineLRScheduler\n",
    "from neurorient.config          import _CONFIG\n",
    "from neurorient.utils_config    import (\n",
    "    prepare_Slice2RotMat_config, prepare_IntensityNet_config, prepare_optimization_config)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)    # [WARNING] Making it True may throw errors when using bfloat16\n",
    "                                            # Reference: https://discuss.pytorch.org/t/convolutionbackward0-returned-nan-values-in-its-0th-output/175571/4\n",
    "                                            \n",
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ ARG ]]]\n",
    "# parser = argparse.ArgumentParser(description=\"Load training configuration from a YAML file to a dictionary.\")\n",
    "# parser.add_argument('-yf', '--yaml_file', help=\"Path to the YAML file\", dest='yaml_file', type=str, required=True)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    yaml_file='/global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config_resnet_coslr_fpcb.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-03 13:31:51] loaded configuration from yaml_file: /global/homes/z/zhantao/Projects/NeuralOrientationMatching/base_config_resnet_coslr_fpcb.yaml.\n",
      "[2023-10-03 13:31:51] overwrite default model configurations with customed configurations.\n",
      "[2023-10-03 13:31:51] SEED set to 42.\n",
      "[2023-10-03 13:31:51] checkpoints will be saved to /pscratch/sd/z/zhantao/neurorient_repo/experiments/transformations.\n",
      "[2023-10-03 13:31:51] data read from 1BXR_increase1_poissonFalse_num10K.pt\n",
      "[2023-10-03 13:31:51] training the model with 1000 epochs and 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "# [[[ HYPER-PARAMERTERS ]]]\n",
    "# Load CONFIG from YAML\n",
    "fl_yaml = args.yaml_file\n",
    "\n",
    "with open(fl_yaml, 'r') as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "CONFIG = Configurator.from_dict(config_dict)\n",
    "logger.log(f\"loaded configuration from yaml_file: {fl_yaml}.\")\n",
    "\n",
    "merged_config = CONFIG.merge_with_priority(_CONFIG, self_has_priority=True)\n",
    "logger.log(f\"overwrite default model configurations with customed configurations.\")\n",
    "\n",
    "\n",
    "if hasattr(merged_config.TRAINING, 'SEED'):\n",
    "    L.seed_everything(merged_config.TRAINING.SEED)\n",
    "    logger.log(f\"SEED set to {merged_config.TRAINING.SEED}.\")\n",
    "else:\n",
    "    logger.log(f\"SEED not specified and not set.\")\n",
    "\n",
    "# ...Checkpoint\n",
    "dir_chkpt           = Path(os.path.join(merged_config.TRAINING.BASE_DIRECTORY, merged_config.TRAINING.CHKPT_DIRECTORY))\n",
    "dir_chkpt.mkdir(parents=True, exist_ok=True)\n",
    "logger.log(f\"checkpoints will be saved to {dir_chkpt}.\")\n",
    "\n",
    "# ...Dataset\n",
    "dir_dataset       = merged_config.DATASET.DATASET_DIRECTORY\n",
    "# necessary info to fetch data file name\n",
    "pdb               = merged_config.DATASET.PDB\n",
    "num_images        = merged_config.DATASET.NUM_IMG\n",
    "data_file_name = f'{pdb}_increase1_poissonFalse_num{num_images//1000}K.pt'\n",
    "logger.log(f'data read from {data_file_name}')\n",
    "\n",
    "# necessary info to define datasets\n",
    "frac_train        = merged_config.DATASET.FRAC_TRAIN\n",
    "size_batch        = merged_config.DATASET.BATCH_SIZE\n",
    "num_workers       = merged_config.DATASET.NUM_WORKERS\n",
    "\n",
    "# ...Training\n",
    "max_epochs           = merged_config.TRAINING.MAX_EPOCHS\n",
    "num_gpus             = min(torch.cuda.device_count(), merged_config.TRAINING.NUM_GPUS)\n",
    "logger.log(f'training the model with {max_epochs} epochs and {num_gpus} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-03 13:31:52] transformation: photon fluctuation applied to training and validation datasets.\n",
      "[2023-10-03 13:31:52] transformation: poisson noise applied to training and validation datasets.\n",
      "[2023-10-03 13:31:52] transformation: beam stop mask applied to training and validation datasets.\n",
      "[2023-10-03 13:31:52] transformation: random patch applied to training and validation datasets.\n",
      "[2023-10-03 13:31:52] 4 transformations applied to training and validation datasets.\n",
      "[2023-10-03 13:31:52] created training dataset with 9000 images and validation dataset with 1000 images.\n"
     ]
    }
   ],
   "source": [
    "# [[[ DATASET ]]]\n",
    "spi_data = torch.load(os.path.join(dir_dataset, data_file_name))\n",
    "\n",
    "# Set global seed and split data...\n",
    "data              = spi_data['intensities'] * merged_config.DATASET.INCREASE_FACTOR\n",
    "spi_data_train    = data[:int(len(data) * frac_train) ]\n",
    "spi_data_validate = data[ int(len(data) * frac_train):]\n",
    "\n",
    "# Set world seed and set up transformation rules\n",
    "uses_random_patch = merged_config.DATASET.USES_RANDOM_PATCH\n",
    "\n",
    "transform_list = []\n",
    "\n",
    "if merged_config.DATASET.USES_PHOTON_FLUCTUATION:\n",
    "    # set up photon fluctuation transformation\n",
    "    photon_fluctuation = PhotonFluctuation(\n",
    "        'neurorient/data/image_distribution_by_photon_count.npy',\n",
    "        return_mask=False)\n",
    "    transform_list.append(photon_fluctuation)\n",
    "    logger.log(f'transformation: photon fluctuation applied to training and validation datasets.')\n",
    "\n",
    "\n",
    "if merged_config.DATASET.USES_POISSON_NOISE:\n",
    "    poisson_noise = PoissonNoise(return_mask=False)\n",
    "    transform_list.append(poisson_noise)\n",
    "    logger.log(f'transformation: poisson noise applied to training and validation datasets.')\n",
    "\n",
    "\n",
    "if merged_config.DATASET.USES_BEAM_STOP_MASK:\n",
    "    beam_stop_mask = BeamStopMask(width              = merged_config.DATASET.BEAM_STOP_MASK.WIDTH, \n",
    "                                  radius             = merged_config.DATASET.BEAM_STOP_MASK.RADIUS, \n",
    "                                  input_size         = data.shape[-2:],\n",
    "                                  mask_orientation   = merged_config.DATASET.BEAM_STOP_MASK.ORIENTATION,\n",
    "                                  return_mask        = True)\n",
    "    transform_list.append(beam_stop_mask)\n",
    "    logger.log(f'transformation: beam stop mask applied to training and validation datasets.')\n",
    "    \n",
    "    \n",
    "if merged_config.DATASET.USES_RANDOM_PATCH:\n",
    "    # set up random patch transformation\n",
    "    num_patch       = merged_config.DATASET.PATCH.NUM_PATCHES\n",
    "    size_patch_min  = merged_config.DATASET.PATCH.SIZE_PATCH_MIN\n",
    "    size_patch_max  = merged_config.DATASET.PATCH.SIZE_PATCH_MAX\n",
    "    random_patch = RandomPatch(num_patch       = num_patch,\n",
    "                               size_patch_min  = size_patch_min,\n",
    "                               size_patch_max  = size_patch_max,\n",
    "                               return_mask     = True)\n",
    "    transform_list.append(random_patch)\n",
    "    logger.log(f'transformation: random patch applied to training and validation datasets.')\n",
    "    \n",
    "    \n",
    "if len(transform_list) > 0:\n",
    "    transform_list   = tuple(transform_list)\n",
    "    dataset_train    = TensorDatasetWithTransform(spi_data_train.unsqueeze(1), transform_list = transform_list)\n",
    "    dataset_validate = TensorDatasetWithTransform(spi_data_validate.unsqueeze(1), transform_list = transform_list)\n",
    "    logger.log(f'{len(transform_list)} transformations applied to training and validation datasets.')\n",
    "else:\n",
    "    dataset_train    = TensorDataset(spi_data_train.unsqueeze(1))\n",
    "    dataset_validate = TensorDataset(spi_data_validate.unsqueeze(1))\n",
    "    logger.log(f'NO random patch transformation applied to training and validation datasets.')\n",
    "\n",
    "logger.log(f'created training dataset with {len(dataset_train)} images and validation dataset with {len(dataset_validate)} images.')\n",
    "\n",
    "\n",
    "# lightning will handle the samplers for those dataloaders\n",
    "sampler_train    = None\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                sampler     = sampler_train,\n",
    "                                                shuffle     = True,\n",
    "                                                pin_memory  = True,\n",
    "                                                batch_size  = size_batch,\n",
    "                                                num_workers = num_workers, )\n",
    "\n",
    "sampler_validate    = None\n",
    "dataloader_validate = torch.utils.data.DataLoader( dataset_validate,\n",
    "                                                   sampler     = sampler_validate,\n",
    "                                                   shuffle     = False,\n",
    "                                                   pin_memory  = True,\n",
    "                                                   batch_size  = size_batch,\n",
    "                                                   num_workers = num_workers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-03 13:31:53] arguments being used in building the model:\n",
      " over_sampling=1.0\n",
      " photons_per_pulse=1.00e+13\n",
      " config_slice2rotmat:  \n",
      " {'pretrained': True, 'size': 18} \n",
      " config_optimization:  \n",
      " {'loss_func': 'MSELoss',\n",
      " 'lr': 0.0003,\n",
      " 'scheduler': {'min_lr': 1e-07,\n",
      "               'name': 'CosineLRScheduler',\n",
      "               'total_epochs': 1000,\n",
      "               'warmup_epochs': 5},\n",
      " 'weight_decay': 0.0001}\n",
      "[2023-10-03 13:31:53] model created with the following architecture:\n",
      " NeurOrientLightning(\n",
      "  (model): NeurOrient(\n",
      "    (orientation_predictor): Slice2RotMat(\n",
      "      (resnet): ResNet(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "        (fc): Linear(in_features=512, out_features=6, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (volume_predictor): IntensityNet(\n",
      "      (net_mag): SirenNet(\n",
      "        (layers): ModuleList(\n",
      "          (0-4): 5 x Siren(\n",
      "            (activation): Sine()\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (last_layer): Siren(\n",
      "          (activation): SiLU()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# [[[ MODEL ]]]\n",
    "over_sampling = merged_config.MODEL.OVERSAMPLING\n",
    "photons_per_pulse = merged_config.DATASET.INCREASE_FACTOR * 1e12\n",
    "config_optimization = prepare_optimization_config(merged_config)\n",
    "config_intensitynet = prepare_IntensityNet_config(merged_config)\n",
    "config_slice2rotmat = prepare_Slice2RotMat_config(merged_config)\n",
    "model = NeurOrientLightning(\n",
    "    spi_data['pixel_position_reciprocal'],\n",
    "    over_sampling=over_sampling, \n",
    "    photons_per_pulse=photons_per_pulse,\n",
    "    use_bifpn=merged_config.MODEL.USE_BIFPN,\n",
    "    config_slice2rotmat=config_slice2rotmat,\n",
    "    config_intensitynet=config_intensitynet,\n",
    "    config_optimization=config_optimization\n",
    ")\n",
    "logger.log( \n",
    "    'arguments being used in building the model:\\n',\n",
    "    f'over_sampling={over_sampling}\\n',\n",
    "    f'photons_per_pulse={photons_per_pulse:.2e}\\n',\n",
    "    'config_slice2rotmat: ', '\\n', pprint.pformat(config_slice2rotmat), '\\n',\n",
    "    'config_optimization: ', '\\n', pprint.pformat(config_optimization))\n",
    "\n",
    "logger.log(\n",
    "    \"model created with the following architecture:\\n\",\n",
    "    pprint.pformat(model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model     | NeurOrient | 11.4 M\n",
      "1 | loss_func | MSELoss    | 0     \n",
      "-----------------------------------------\n",
      "11.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.751    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd18b39e83f4f78af9b4cd618b322db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f90d95c1e54f6db4e53646ecaf1c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:359: UserWarning: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d4011fb2834ea68d6aba1a1f4f6874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936b0529660e456ba2eec268273594e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"val_loss\",\n",
    "    filename=f'{pdb}-{{epoch}}-{{step}}'\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs, accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=num_gpus,\n",
    "    enable_checkpointing=True, default_root_dir=dir_chkpt)\n",
    "\n",
    "# dump configuration to file for later reference\n",
    "dump_yaml_fname = Path(os.path.join(trainer.logger.save_dir, 'lightning_logs', f'version_{trainer.logger.version}', 'input.yaml'))\n",
    "dump_yaml_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "merged_config.dump_to_file(dump_yaml_fname)\n",
    "\n",
    "dump_log_fname = Path(os.path.join(trainer.logger.save_dir, 'lightning_logs', f'version_{trainer.logger.version}', 'log.txt'))\n",
    "dump_log_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "logger.dump_to_file(dump_log_fname)\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "om",
   "language": "python",
   "name": "om"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
