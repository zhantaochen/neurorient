{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to verify the configurator.py file.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from lightning.pytorch.strategies import DDPStrategy\n",
    "\n",
    "from neurorient.model           import NeurOrientLightning\n",
    "from neurorient.dataset         import TensorDatasetWithTransform, DictionaryDataset\n",
    "from neurorient.logger          import Logger\n",
    "from neurorient.image_transform import RandomPatch, PhotonFluctuation, PoissonNoise, GaussianNoise, BeamStopMask\n",
    "from neurorient.configurator    import Configurator\n",
    "# from neurorient.lr_scheduler    import CosineLRScheduler\n",
    "from neurorient.config          import _CONFIG\n",
    "from neurorient.utils_config    import (\n",
    "    prepare_Slice2RotMat_config, prepare_IntensityNet_config, prepare_optimization_config)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)    # [WARNING] Making it True may throw errors when using bfloat16\n",
    "                                            # Reference: https://discuss.pytorch.org/t/convolutionbackward0-returned-nan-values-in-its-0th-output/175571/4\n",
    "                                            \n",
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[[ ARG ]]]\n",
    "# parser = argparse.ArgumentParser(description=\"Load training configuration from a YAML file to a dictionary.\")\n",
    "# parser.add_argument('-yf', '--yaml_file', help=\"Path to the YAML file\", dest='yaml_file', type=str, required=True)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    yaml_file='yaml/3iyf_resnet18_100x_coslr_fp.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-27 07:04:22] loaded configuration from yaml_file: yaml/3iyf_resnet18_100x_coslr_fp.yaml.\n",
      "\n",
      "[2023-10-27 07:04:22] overwrite default model configurations with customed configurations.\n",
      "\n",
      "[2023-10-27 07:04:22] SEED set to 42.\n",
      "\n",
      "[2023-10-27 07:04:22] checkpoints will be saved to /pscratch/sd/z/zhantao/neurorient_repo/experiments/transformations_fluctuation_pred.\n",
      "\n",
      "[2023-10-27 07:04:22] data read from 3IYF_increase1_poissonFalse_num10K.pt\n",
      "\n",
      "[2023-10-27 07:04:22] training the model with 1000 epochs and 1 GPUs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [[[ HYPER-PARAMERTERS ]]]\n",
    "# Load CONFIG from YAML\n",
    "fl_yaml = args.yaml_file\n",
    "\n",
    "with open(fl_yaml, 'r') as fh:\n",
    "    config_dict = yaml.safe_load(fh)\n",
    "CONFIG = Configurator.from_dict(config_dict)\n",
    "logger.log(f\"loaded configuration from yaml_file: {fl_yaml}.\")\n",
    "\n",
    "merged_config = CONFIG.merge_with_priority(_CONFIG, self_has_priority=True)\n",
    "logger.log(f\"overwrite default model configurations with customed configurations.\")\n",
    "\n",
    "\n",
    "if hasattr(merged_config.TRAINING, 'SEED'):\n",
    "    L.seed_everything(merged_config.TRAINING.SEED)\n",
    "    logger.log(f\"SEED set to {merged_config.TRAINING.SEED}.\")\n",
    "else:\n",
    "    logger.log(f\"SEED not specified and not set.\")\n",
    "\n",
    "# ...Checkpoint\n",
    "dir_chkpt           = Path(os.path.join(merged_config.TRAINING.BASE_DIRECTORY, merged_config.TRAINING.CHKPT_DIRECTORY))\n",
    "dir_chkpt.mkdir(parents=True, exist_ok=True)\n",
    "logger.log(f\"checkpoints will be saved to {dir_chkpt}.\")\n",
    "\n",
    "# ...Dataset\n",
    "dir_dataset       = merged_config.DATASET.DATASET_DIRECTORY\n",
    "# necessary info to fetch data file name\n",
    "pdb               = merged_config.DATASET.PDB\n",
    "num_images        = merged_config.DATASET.NUM_IMG\n",
    "data_file_name = f'{pdb}_increase1_poissonFalse_num{num_images//1000}K.pt'\n",
    "logger.log(f'data read from {data_file_name}')\n",
    "\n",
    "# necessary info to define datasets\n",
    "if hasattr(merged_config.DATASET, 'FRAC_TOTAL'):\n",
    "    frac_total        = merged_config.DATASET.FRAC_TOTAL\n",
    "else:\n",
    "    frac_total        = 1.0\n",
    "frac_train        = merged_config.DATASET.FRAC_TRAIN\n",
    "size_batch        = merged_config.DATASET.BATCH_SIZE\n",
    "num_workers       = merged_config.DATASET.NUM_WORKERS\n",
    "\n",
    "# ...Training\n",
    "max_epochs           = merged_config.TRAINING.MAX_EPOCHS\n",
    "num_gpus             = min(torch.cuda.device_count(), merged_config.TRAINING.NUM_GPUS)\n",
    "logger.log(f'training the model with {max_epochs} epochs and {num_gpus} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-27 07:04:23] transformation: photon fluctuation applied to training and validation datasets.\n",
      "\n",
      "[2023-10-27 07:04:23] transformation: poisson noise applied to training and validation datasets.\n",
      "\n",
      "[2023-10-27 07:04:23] 2 transformations applied to training and validation datasets.\n",
      "\n",
      "[2023-10-27 07:04:34] created dictionary datasets for training and validation.\n",
      "\n",
      "[2023-10-27 07:04:34] created training dataset with 9500 images and validation dataset with 500 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [[[ DATASET ]]]\n",
    "spi_data = torch.load(os.path.join(dir_dataset, data_file_name))\n",
    "\n",
    "# Set global seed and split data...\n",
    "total_num_data = len(spi_data['intensities'])\n",
    "data              = spi_data['intensities'][:int(total_num_data * frac_total)] * merged_config.DATASET.INCREASE_FACTOR\n",
    "spi_data_train    = data[:int(len(data) * frac_train) ]\n",
    "spi_data_validate = data[ int(len(data) * frac_train):]\n",
    "\n",
    "transform_list = []\n",
    "\n",
    "if merged_config.DATASET.USES_PHOTON_FLUCTUATION:\n",
    "    # set up photon fluctuation transformation\n",
    "    photon_fluctuation = PhotonFluctuation(\n",
    "        'neurorient/data/image_distribution_by_photon_count.npy',\n",
    "        return_mask=False)\n",
    "    transform_list.append(photon_fluctuation)\n",
    "    logger.log(f'transformation: photon fluctuation applied to training and validation datasets.')\n",
    "\n",
    "\n",
    "if merged_config.DATASET.USES_POISSON_NOISE:\n",
    "    poisson_noise = PoissonNoise(return_mask=False)\n",
    "    transform_list.append(poisson_noise)\n",
    "    logger.log(f'transformation: poisson noise applied to training and validation datasets.')\n",
    "\n",
    "\n",
    "if merged_config.DATASET.USES_GAUSSIAN_NOISE:\n",
    "    gaussian_noise = GaussianNoise(sigma=merged_config.DATASET.GAUSSIAN_NOISE.SIGMA, return_mask=False)\n",
    "    transform_list.append(gaussian_noise)\n",
    "    logger.log(f'transformation: gaussian noise applied to training and validation datasets.')\n",
    "\n",
    "\n",
    "if merged_config.DATASET.USES_BEAM_STOP_MASK:\n",
    "    beam_stop_mask = BeamStopMask(width              = merged_config.DATASET.BEAM_STOP_MASK.WIDTH, \n",
    "                                  radius             = merged_config.DATASET.BEAM_STOP_MASK.RADIUS, \n",
    "                                  input_size         = data.shape[-2:],\n",
    "                                  mask_orientation   = merged_config.DATASET.BEAM_STOP_MASK.ORIENTATION,\n",
    "                                  return_mask        = True)\n",
    "    transform_list.append(beam_stop_mask)\n",
    "    logger.log(f'transformation: beam stop mask applied to training and validation datasets.')\n",
    "    \n",
    "    \n",
    "if merged_config.DATASET.USES_RANDOM_PATCH:\n",
    "    # set up random patch transformation\n",
    "    num_patch       = merged_config.DATASET.PATCH.NUM_PATCHES\n",
    "    size_patch_min  = merged_config.DATASET.PATCH.SIZE_PATCH_MIN\n",
    "    size_patch_max  = merged_config.DATASET.PATCH.SIZE_PATCH_MAX\n",
    "    random_patch = RandomPatch(num_patch       = num_patch,\n",
    "                               size_patch_min  = size_patch_min,\n",
    "                               size_patch_max  = size_patch_max,\n",
    "                               return_mask     = True)\n",
    "    transform_list.append(random_patch)\n",
    "    logger.log(f'transformation: random patch applied to training and validation datasets.')\n",
    "    \n",
    "    \n",
    "if len(transform_list) > 0:\n",
    "    transform_list   = tuple(transform_list)\n",
    "    _dataset_train    = TensorDatasetWithTransform(\n",
    "        spi_data_train.unsqueeze(1), transform_list = transform_list, seed=merged_config.TRAINING.SEED)\n",
    "    _dataset_validate = TensorDatasetWithTransform(\n",
    "        spi_data_validate.unsqueeze(1), transform_list = transform_list, seed=merged_config.TRAINING.SEED)\n",
    "    \n",
    "    logger.log(f'{len(transform_list)} transformations applied to training and validation datasets.')\n",
    "    \n",
    "    train_data = {key: [] for key in _dataset_train[0].keys()}\n",
    "    for i, d in enumerate(_dataset_train):\n",
    "        for _key in d.keys():\n",
    "            train_data[_key].append(d[_key])\n",
    "    for _key in train_data.keys():\n",
    "        train_data[_key] = torch.stack(train_data[_key], dim=0)\n",
    "    dataset_train = DictionaryDataset(**train_data)\n",
    "    del train_data\n",
    "    \n",
    "    validate_data = {key: [] for key in _dataset_validate[0].keys()}\n",
    "    for i, d in enumerate(_dataset_validate):\n",
    "        for _key in d.keys():\n",
    "            validate_data[_key].append(d[_key])\n",
    "    for _key in validate_data.keys():\n",
    "        validate_data[_key] = torch.stack(validate_data[_key], dim=0)\n",
    "    dataset_validate = DictionaryDataset(**validate_data)\n",
    "    del validate_data\n",
    "    \n",
    "    logger.log(f'created dictionary datasets for training and validation.')\n",
    "else:\n",
    "    dataset_train    = TensorDataset(spi_data_train.unsqueeze(1))\n",
    "    dataset_validate = TensorDataset(spi_data_validate.unsqueeze(1))\n",
    "    logger.log(f'NO random patch transformation applied to training and validation datasets.')\n",
    "\n",
    "logger.log(f'created training dataset with {len(dataset_train)} images and validation dataset with {len(dataset_validate)} images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# lightning will handle the samplers for those dataloaders\n",
    "sampler_train    = None\n",
    "dataloader_train = torch.utils.data.DataLoader( dataset_train,\n",
    "                                                sampler     = sampler_train,\n",
    "                                                shuffle     = True,\n",
    "                                                pin_memory  = True,\n",
    "                                                batch_size  = size_batch,\n",
    "                                                num_workers = num_workers, )\n",
    "\n",
    "sampler_validate    = None\n",
    "dataloader_validate = torch.utils.data.DataLoader( dataset_validate,\n",
    "                                                   sampler     = sampler_validate,\n",
    "                                                   shuffle     = False,\n",
    "                                                   pin_memory  = True,\n",
    "                                                   batch_size  = size_batch,\n",
    "                                                   num_workers = num_workers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-27 07:04:35] arguments being used in building the model:\n",
      " over_sampling=1.0\n",
      " photons_per_pulse=1.00e+14\n",
      " config_slice2rotmat:  \n",
      " {'pretrained': True, 'size': 18} \n",
      " config_optimization:  \n",
      " {'loss_func': 'MSELoss',\n",
      " 'lr': 0.0003,\n",
      " 'scheduler': {'min_lr': 1e-07,\n",
      "               'name': 'CosineLRScheduler',\n",
      "               'total_epochs': 1000,\n",
      "               'warmup_epochs': 5},\n",
      " 'weight_decay': 0.0001}\n",
      "\n",
      "[2023-10-27 07:04:35] model created with the following architecture:\n",
      " NeurOrientLightning(\n",
      "  (model): NeurOrient(\n",
      "    (orientation_predictor): Slice2RotMat(\n",
      "      (resnet): ResNet(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "        (fc): Linear(in_features=512, out_features=6, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (fluctuation_predictor): FluctuationPredictor(\n",
      "      (resnet): ResNet(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "        (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "      )\n",
      "      (output_relu): ReLU()\n",
      "    )\n",
      "    (volume_predictor): IntensityNet(\n",
      "      (net_mag): SirenNet(\n",
      "        (layers): ModuleList(\n",
      "          (0-4): 5 x Siren(\n",
      "            (activation): Sine()\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (last_layer): Siren(\n",
      "          (activation): ReLU()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): MSELoss()\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [[[ MODEL ]]]\n",
    "over_sampling = merged_config.MODEL.OVERSAMPLING\n",
    "photons_per_pulse = merged_config.DATASET.INCREASE_FACTOR * 1e12\n",
    "config_optimization = prepare_optimization_config(merged_config)\n",
    "config_intensitynet = prepare_IntensityNet_config(merged_config)\n",
    "config_slice2rotmat = prepare_Slice2RotMat_config(merged_config)\n",
    "model = NeurOrientLightning(\n",
    "    spi_data['pixel_position_reciprocal'],\n",
    "    over_sampling=over_sampling, \n",
    "    photons_per_pulse=photons_per_pulse,\n",
    "    use_bifpn=merged_config.MODEL.USE_BIFPN,\n",
    "    use_fluctuation_predictor=True if merged_config.DATASET.USES_PHOTON_FLUCTUATION else False,\n",
    "    config_slice2rotmat=config_slice2rotmat,\n",
    "    config_intensitynet=config_intensitynet,\n",
    "    config_optimization=config_optimization\n",
    ")\n",
    "logger.log( \n",
    "    'arguments being used in building the model:\\n',\n",
    "    f'over_sampling={over_sampling}\\n',\n",
    "    f'photons_per_pulse={photons_per_pulse:.2e}\\n',\n",
    "    'config_slice2rotmat: ', '\\n', pprint.pformat(config_slice2rotmat), '\\n',\n",
    "    'config_optimization: ', '\\n', pprint.pformat(config_optimization))\n",
    "\n",
    "logger.log(\n",
    "    \"model created with the following architecture:\\n\",\n",
    "    pprint.pformat(model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-p ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-p ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | model     | NeurOrient | 22.6 M\n",
      "1 | loss_func | MSELoss    | 0     \n",
      "-----------------------------------------\n",
      "22.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.6 M    Total params\n",
      "90.434    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb92dea211da459bb5871f95406aad54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9896135d274f319eb6c410208e68a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:359: UserWarning: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d119ca7ed28349f38c95c1a5c370f093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4415de8e1f83407c979dffa62d963d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cb75036ff04b69bbdb8e8f037d93f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245c635bc7ab451184b8568e1b3b6c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106b0f0caabe457fbf73ccf36e652906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163b82b59ec748769a2536673647f61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6ff89211f945a6bf27577aeb78c2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de5eaeb85c7499f86409a9ba0931b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3da5e0a8874207a9b1ebbc48c26450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"val_loss\",\n",
    "    filename=f'{pdb}-{{epoch}}-{{step}}'\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "ddp = DDPStrategy(process_group_backend=\"nccl\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs, accelerator='gpu',\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=num_gpus, sync_batchnorm = True,\n",
    "    enable_checkpointing=True, default_root_dir=dir_chkpt)\n",
    "\n",
    "# dump configuration to file for later reference\n",
    "dump_yaml_fname = Path(os.path.join(trainer.logger.log_dir, 'input.yaml'))\n",
    "dump_yaml_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "merged_config.dump_to_file(dump_yaml_fname)\n",
    "\n",
    "dump_log_fname = Path(os.path.join(trainer.logger.log_dir, 'log.txt'))\n",
    "dump_log_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "logger.dump_to_file(dump_log_fname)\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-p ...\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy=<lightning.pytorch.strategies.ddp.DDPStrategy object at 0x7f241564eb80>)` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: `Fabric(strategy='dp'|'ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m torch\u001b[39m.\u001b[39mset_float32_matmul_precision(\u001b[39m'\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m ddp \u001b[39m=\u001b[39m DDPStrategy(process_group_backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnccl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m trainer \u001b[39m=\u001b[39m L\u001b[39m.\u001b[39;49mTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mmax_epochs, accelerator\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m'\u001b[39;49m, strategy\u001b[39m=\u001b[39;49mddp,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback, TQDMProgressBar(refresh_rate\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, devices\u001b[39m=\u001b[39;49mnum_gpus, sync_batchnorm \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     enable_checkpointing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, default_root_dir\u001b[39m=\u001b[39;49mdir_chkpt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# dump configuration to file for later reference\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bperlmutter-p1.nersc.gov/global/homes/z/zhantao/Projects/NeuralOrientationMatching/verify_configurator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m dump_yaml_fname \u001b[39m=\u001b[39m Path(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(trainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog_dir, \u001b[39m'\u001b[39m\u001b[39minput.yaml\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:399\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m _DataConnector(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m _AcceleratorConnector(\n\u001b[1;32m    400\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    401\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    402\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    403\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    404\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    405\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    406\u001b[0m     use_distributed_sampler\u001b[39m=\u001b[39;49muse_distributed_sampler,\n\u001b[1;32m    407\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    408\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    409\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    410\u001b[0m )\n\u001b[1;32m    411\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m _LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[1;32m    412\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m _CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:173\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    172\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m/pscratch/sd/z/zhantao/conda/om/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:576\u001b[0m, in \u001b[0;36m_AcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_configure_launcher()\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    577\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy_flag\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Fabric(strategy=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mddp_notebook\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    587\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, XLAStrategy)\n\u001b[1;32m    588\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy=<lightning.pytorch.strategies.ddp.DDPStrategy object at 0x7f241564eb80>)` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: `Fabric(strategy='dp'|'ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"val_loss\",\n",
    "    filename=f'{pdb}-{{epoch}}-{{step}}'\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "ddp = DDPStrategy(process_group_backend=\"nccl\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=max_epochs, accelerator='gpu', strategy=ddp,\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=num_gpus, sync_batchnorm = True,\n",
    "    enable_checkpointing=True, default_root_dir=dir_chkpt)\n",
    "\n",
    "# dump configuration to file for later reference\n",
    "dump_yaml_fname = Path(os.path.join(trainer.logger.log_dir, 'input.yaml'))\n",
    "dump_yaml_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "merged_config.dump_to_file(dump_yaml_fname)\n",
    "\n",
    "dump_log_fname = Path(os.path.join(trainer.logger.log_dir, 'log.txt'))\n",
    "dump_log_fname.parent.mkdir(parents=True, exist_ok=True)\n",
    "logger.dump_to_file(dump_log_fname)\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
