{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from neurorient import NeurOrient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['orientations', 'images', 'angles', 'points', 'pixel_position_reciprocal', 'volume', 'img_real_mesh', 'vol_real_mesh'])\n"
     ]
    }
   ],
   "source": [
    "spi_data = torch.load('/pscratch/sd/z/zhantao/neurorient_repo/data/1bxr_train.pt')\n",
    "model_dir = '/pscratch/sd/z/zhantao/neurorient_repo/model'\n",
    "print(spi_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 16x2\n",
      "start building 1\n",
      "layer 1 built\n",
      "start building 2\n",
      "layer 2 built\n",
      "start building 3\n",
      "layer 3 built\n",
      "MODEL TOPOLOGY:\n",
      "\t0 - \n",
      "\t1 - conv1\n",
      "\t2 - conv1._basisexpansion\n",
      "\t3 - conv1._basisexpansion.block_expansion_('irrep_0', 'regular')\n",
      "\t4 - layer1\n",
      "\t5 - layer1.0\n",
      "\t6 - layer1.0.bn1\n",
      "\t7 - layer1.0.bn1.batch_norm_[8]\n",
      "\t8 - layer1.0.relu1\n",
      "\t9 - layer1.0.conv1\n",
      "\t10 - layer1.0.conv1._basisexpansion\n",
      "\t11 - layer1.0.conv1._basisexpansion.block_expansion_('regular', 'regular')\n",
      "\t12 - layer1.0.bn2\n",
      "\t13 - layer1.0.bn2.batch_norm_[8]\n",
      "\t14 - layer1.0.relu2\n",
      "\t15 - layer1.0.dropout\n",
      "\t16 - layer1.0.conv2\n",
      "\t17 - layer1.0.conv2._basisexpansion\n",
      "\t18 - layer1.0.shortcut\n",
      "\t19 - layer1.0.shortcut._basisexpansion\n",
      "\t20 - layer1.0.shortcut._basisexpansion.block_expansion_('regular', 'regular')\n",
      "\t21 - layer1.1\n",
      "\t22 - layer1.1.bn1\n",
      "\t23 - layer1.1.bn1.batch_norm_[8]\n",
      "\t24 - layer1.1.relu1\n",
      "\t25 - layer1.1.conv1\n",
      "\t26 - layer1.1.bn2\n",
      "\t27 - layer1.1.bn2.batch_norm_[8]\n",
      "\t28 - layer1.1.relu2\n",
      "\t29 - layer1.1.dropout\n",
      "\t30 - layer1.1.conv2\n",
      "\t31 - layer2\n",
      "\t32 - layer2.0\n",
      "\t33 - layer2.0.bn1\n",
      "\t34 - layer2.0.bn1.batch_norm_[8]\n",
      "\t35 - layer2.0.relu1\n",
      "\t36 - layer2.0.conv1\n",
      "\t37 - layer2.0.conv1._basisexpansion\n",
      "\t38 - layer2.0.bn2\n",
      "\t39 - layer2.0.bn2.batch_norm_[8]\n",
      "\t40 - layer2.0.relu2\n",
      "\t41 - layer2.0.dropout\n",
      "\t42 - layer2.0.conv2\n",
      "\t43 - layer2.0.conv2._basisexpansion\n",
      "\t44 - layer2.0.shortcut\n",
      "\t45 - layer2.0.shortcut._basisexpansion\n",
      "\t46 - layer2.1\n",
      "\t47 - layer2.1.bn1\n",
      "\t48 - layer2.1.bn1.batch_norm_[8]\n",
      "\t49 - layer2.1.relu1\n",
      "\t50 - layer2.1.conv1\n",
      "\t51 - layer2.1.bn2\n",
      "\t52 - layer2.1.bn2.batch_norm_[8]\n",
      "\t53 - layer2.1.relu2\n",
      "\t54 - layer2.1.dropout\n",
      "\t55 - layer2.1.conv2\n",
      "\t56 - layer3\n",
      "\t57 - layer3.0\n",
      "\t58 - layer3.0.bn1\n",
      "\t59 - layer3.0.bn1.batch_norm_[8]\n",
      "\t60 - layer3.0.relu1\n",
      "\t61 - layer3.0.conv1\n",
      "\t62 - layer3.0.conv1._basisexpansion\n",
      "\t63 - layer3.0.bn2\n",
      "\t64 - layer3.0.bn2.batch_norm_[8]\n",
      "\t65 - layer3.0.relu2\n",
      "\t66 - layer3.0.dropout\n",
      "\t67 - layer3.0.conv2\n",
      "\t68 - layer3.0.conv2._basisexpansion\n",
      "\t69 - layer3.0.shortcut\n",
      "\t70 - layer3.0.shortcut._basisexpansion\n",
      "\t71 - layer3.1\n",
      "\t72 - layer3.1.bn1\n",
      "\t73 - layer3.1.bn1.batch_norm_[8]\n",
      "\t74 - layer3.1.relu1\n",
      "\t75 - layer3.1.conv1\n",
      "\t76 - layer3.1.bn2\n",
      "\t77 - layer3.1.bn2.batch_norm_[8]\n",
      "\t78 - layer3.1.relu2\n",
      "\t79 - layer3.1.dropout\n",
      "\t80 - layer3.1.conv2\n",
      "\t81 - layer3.1.conv2._basisexpansion\n",
      "\t82 - layer3.1.conv2._basisexpansion.block_expansion_('regular', 'irrep_0')\n",
      "\t83 - layer3.1.shortcut\n",
      "\t84 - layer3.1.shortcut._basisexpansion\n",
      "\t85 - layer3.1.shortcut._basisexpansion.block_expansion_('regular', 'irrep_0')\n",
      "\t86 - bn\n",
      "\t87 - bn.batch_norm_[1]\n",
      "\t88 - relu\n"
     ]
    }
   ],
   "source": [
    "model = NeurOrient(spi_data['pixel_position_reciprocal'], path=model_dir)\n",
    "model.to('cpu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compute_autocorrelation()\n",
    "# orientations = model.image_to_orientation(spi_data['images'][:10].unsqueeze(1))\n",
    "# from neurorient.reconstruction.slicing import get_rho_function\n",
    "# rho_true = torch.fft.fftshift(torch.fft.ifftn(torch.fft.ifftshift(spi_data['volume']))).real.clip(0)\n",
    "# rho_func = get_rho_function(spi_data['vol_real_mesh'], rho_true)\n",
    "# rho_img_coords = torch.from_numpy(rho_func(spi_data['img_real_mesh'].numpy()))\n",
    "# rho_true = torch.from_numpy(rho_func(model.grid_position_real.numpy()))\n",
    "# ac = model.compute_autocorrelation(rho=rho_true)\n",
    "# slices = model.gen_slices(ac, orientations)\n",
    "# plt.imshow(slices.detach().numpy()[0].clip(0), vmax=slices.max() * 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(spi_data['images'].unsqueeze(1))\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(dataloader))\n",
    "# model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurorient.utils_visualization import display_images_in_parallel, display_volumes\n",
    "\n",
    "# display_images_in_parallel(torch.randn(10, 3,3), torch.randn(10, 3,3))\n",
    "display_volumes(torch.randn(10, 3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type     | Params\n",
      "---------------------------------------------------\n",
      "0 | orientation_predictor | I2S      | 2.1 M \n",
      "1 | rho_predictor         | SirenNet | 264 K \n",
      "2 | nufft_forward         | KbNufft  | 0     \n",
      "---------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.338     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 5/1000 [03:10<10:30:30, 38.02s/it, v_num=12]"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=10, accelerator='cpu',\n",
    "    log_every_n_steps=1, devices=torch.cuda.device_count(),\n",
    "    enable_checkpointing=True, default_root_dir=model.path)\n",
    "trainer.fit(model, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
