from cupyx.scipy.interpolate import RegularGridInterpolator

import numpy as np
import cupy as cp

import scipy
import skopi as sk
import torch
from tqdm import tqdm
from pytorch3d.transforms import quaternion_to_matrix, so3_relative_angle, matrix_to_quaternion

from .utils_transform import convert_to_cupy, convert_to_torch
from .reconstruction.slicing import real_mesh_2_reciprocal_mesh
from .external.spinifel import align_volumes


def find_crossings(qshell, fsc, value=0.5):
    # Code generated by OpenAI's GPT-4
    # Find regions where fsc crosses 0.5
    crossings = np.where(np.diff(np.sign(fsc - value)))[0]
    
    q_crossings = []
    for idx in crossings:
        # Linearly interpolate q value for crossing
        q1, q2 = qshell[idx], qshell[idx + 1]
        f1, f2 = fsc[idx], fsc[idx + 1]
        
        q_cross = q1 + (q2 - q1) * (value - f1) / (f2 - f1)
        q_crossings.append(q_cross)
    
    return q_crossings

def compute_fsc(
        volume1,
        mesh1,
        volume2,
        mesh2=None,
        volume_type='electron_density',
        q_spacing=0.01,
        align_zoom=0.5,
        align_n_search=420):
    """
    Taken from https://gitlab.osti.gov/mtip/spinifel/-/blob/master/eval/fsc.py?ref_type=heads

    Compute the Fourier shell correlation (FSC) curve, with the
    estimated resolution based on a threshold of 0.5.

    Parameters
    ----------
    volume1 : numpy.ndarray, shape (n,n,n)
        reference map
    volume2 : numpy.ndarray, shape (n,n,n)
        reconstructed map
    distance_reciprocal_max : float
        maximum voxel resolution in inverse Angstrom
    q_spacing : float
        q_spacing for evaluating FSC in inverse Angstrom

    Returns
    -------
    resolution : float
        estimated resolution of reconstructed map in Angstroms
    """

    volume1 = convert_to_cupy(volume1)
    volume2 = convert_to_cupy(volume2)
    mesh1 = convert_to_cupy(mesh1)

    if mesh2 is None:
        assert volume1.shape == volume2.shape, "Volumes must be the same shape if mesh2 is not provided."
        mesh_major = mesh1
    else:
        mesh2 = convert_to_cupy(mesh2)
        if mesh2.max() > mesh1.max():
            func_vol2 = RegularGridInterpolator((mesh2[:, 0, 0, 0], mesh2[0, :, 0, 1], mesh2[0, 0, :, 2]), volume2, bounds_error=False, fill_value=0.)
            volume2 = func_vol2(mesh1)
            mesh_major = mesh1
        else:
            func_vol1 = RegularGridInterpolator((mesh1[:, 0, 0, 0], mesh1[0, :, 0, 1], mesh1[0, 0, :, 2]), volume1, bounds_error=False, fill_value=0.)
            volume1 = func_vol1(mesh2)
            mesh_major = mesh2

    # align volumes
    volume1, volume2, aligned_cc, opt_q = align_volumes(
        volume1, volume2, zoom=align_zoom, n_search=align_n_search)
    volume1 = convert_to_cupy(volume1)

    if volume_type == 'electron_density':
        mesh = convert_to_cupy(real_mesh_2_reciprocal_mesh(convert_to_torch(mesh_major)))
        ft1 = cp.fft.fftshift(cp.fft.fftn(volume1)).reshape(-1)
        ft2 = cp.conjugate(cp.fft.fftshift(cp.fft.fftn(volume2)).reshape(-1))
    elif volume_type == 'intensity':
        mesh = mesh_major
        ft1 = cp.sqrt(volume1.clip(0.)).reshape(-1)
        ft2 = cp.sqrt(volume2.clip(0.)).reshape(-1)
    
    q_spacing = min(1.05e-10*(mesh[1,0,0,0] - mesh[0,0,0,0]).get(), q_spacing)

    smags = cp.linalg.norm(cp.array(mesh), axis=-1).reshape(-1) * 1e-10
    q_bounds = cp.arange(0, smags.max() / cp.sqrt(3), q_spacing)
    q_centers = (q_bounds[:-1] + q_bounds[1:]) / 2

    fsc = cp.zeros(len(q_bounds)-1)

    for i, r in enumerate(q_bounds[:-1]):
        indices = cp.where((smags > r) & (smags < r + q_spacing))[0]
        numerator = cp.sum(ft1[indices] * ft2[indices])
        denominator = cp.sqrt(
            cp.sum(
                cp.square(
                    cp.abs(
                        ft1[indices]))) *
            cp.sum(
                    cp.square(
                        cp.abs(
                            ft2[indices]))))
        fsc[i] = numerator.real / (denominator + 1e-12)

    if not isinstance(fsc, np.ndarray):
        fsc = fsc.get()
        q_centers = q_centers.get()

    crossings = find_crossings(q_centers, fsc, value=0.5)
    if len(crossings) == 0 and fsc.min() > 0.5:
        resolution = 1.0 / q_centers[-1]
        print(f"Estimated resolution from largest-q: at least {resolution:.1f} Angstrom")
    elif len(crossings) == 0 and fsc.min() < 0.5:
        resolution = -1
        print("Resolution could be too bad to be estimated.")
    elif len(crossings) == 1:
        resolution = 1 / crossings[0]
        print(f"Estimated resolution from FSC: {resolution:.1f} Angstrom")
    elif len(crossings) > 1:
        resolution = 1 / crossings[0]
        print(f"Estimated resolution from FSC: {resolution:.1f} Angstrom")
        print(f"Multiple crossings detected. Resolution may be underestimated. The best resolution would be {1/crossings[-1]:.1f} Angstrom")

    # f = scipy.interpolate.interp1d(fsc, q_centers, bounds_error=False)
    # try:
    #     resolution = 1.0 / f(0.5)
    #     print(f"Estimated resolution from FSC: {resolution:.1f} Angstrom")
    # except ValueError:
    #     if fsc.min() > 0.5:
    #         resolution = 1.0 / q_centers[-1]
    #         print(f"Estimated resolution from largest-q: at least {resolution:.1f} Angstrom")
    #     else:
    #         resolution = -1
    #         print("Resolution could not be estimated.")

    return resolution, q_centers, fsc, opt_q


# def score_rotmat(rotmat1, rotmat2, rotmat_candidate):
#     angle_error = []
#     for _rotmat in rotmat_candidate:
#         angle_error.append(
#             so3_relative_angle(
#                 torch.einsum("lij, jk -> lik", rotmat1, _rotmat), 
#                 rotmat2).mean()
#             )
#     return torch.stack(angle_error)

# def scan_orientations_fine(
#         rotmat1,
#         rotmat2,
#         opt_rotmat,
#         prev_angle_error,
#         n_iterations=10,
#         n_search=420):
    
#     # perform a series of fine alignment, ending if CC no longer improves
#     sigmas = 2 - 0.2 * np.arange(1, 10)
#     for n in tqdm(range(1, n_iterations)):
#         rotmat_candidate = quaternion_to_matrix(torch.from_numpy(
#             sk.get_preferred_orientation_quat(float(sigmas[n - 1]), n_search - 1, base_quat=matrix_to_quaternion(opt_rotmat).detach().cpu().numpy())
#             )).to(opt_rotmat)
#         rotmat_candidate = torch.vstack((opt_rotmat[None], rotmat_candidate))
#         angle_error = score_rotmat(rotmat1, rotmat2, rotmat_candidate)
#         if angle_error.min().item() > prev_angle_error:
#             break
#         else:
#             opt_rotmat = rotmat_candidate[angle_error.argmin()]
#         #print(torch.max(ccs), opt_q) # useful for debugging
#         prev_score = angle_error.min().item()

#     return opt_rotmat, prev_score

# def align_rotation_matrices(rotmat1, rotmat2, n_search=420, nscs=1, n_iterations=10):

#     # perform a coarse alignment to start
#     rotmat_candidate = quaternion_to_matrix(torch.from_numpy(sk.get_uniform_quat(n_search))).to(rotmat1)
#     angle_error = score_rotmat(rotmat1, rotmat2, rotmat_candidate)
#     ae_order = angle_error.argsort()

#     # scan the top solutions
#     opt_rotmat_list, ae_list = torch.zeros((nscs, 3, 3)).to(rotmat1), torch.zeros(nscs).to(rotmat1)
#     for n in range(nscs):
#         start_q, start_ae = rotmat_candidate[ae_order[n]], angle_error[ae_order[n]]
#         opt_rotmat_list[n], ae_list[n] = scan_orientations_fine(
#             rotmat1, rotmat2, start_q, start_ae, n_iterations=n_iterations, n_search=n_search)

#     opt_rotmat, final_ae = opt_rotmat_list[torch.argmin(ae_list)], torch.min(ae_list)
#     return opt_rotmat, final_ae
